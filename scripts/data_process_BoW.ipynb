{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk138/miniconda3/envs/general/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from timm.data import create_transform\n",
    "import torch\n",
    "import numpy as np\n",
    "from fast_slic.avx2 import SlicAvx2\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      ")\n",
      "Program execution canceled. Please change pathing inputs to save to a new directory.\n"
     ]
    }
   ],
   "source": [
    "# User variables\n",
    "data_path = \"/home/sk138/data/\"\n",
    "data_folder_name = \"cifar-100-python/\"\n",
    "\n",
    "save_path = \"/home/sk138/data/cifar-100-python-segmented/\"\n",
    "input_size = 224\n",
    "num_workers = 10\n",
    "n_segments=196\n",
    "pin_mem = True\n",
    "batch_size=2000\n",
    "DEVICE='cuda:1'\n",
    "\n",
    "# Pathing\n",
    "save_parent = f\"cifar-{n_segments}-BoW-rect/\"\n",
    "full_save_path = os.path.join(save_path, save_parent)\n",
    "\n",
    "# Transforms - do not do the normalization\n",
    "train_transform = create_transform(input_size, is_training=True, no_aug=True)\n",
    "test_transform = create_transform(input_size, is_training=False, no_aug=True)\n",
    "\n",
    "train_transform.transforms = train_transform.transforms[:-1]\n",
    "test_transform.transforms = test_transform.transforms[:-1]\n",
    "\n",
    "grayscale_transform = transforms.Grayscale()\n",
    "\n",
    "# stats = torch.load('train_stats.pt')\n",
    "# standard_transform_mag = transforms.Normalize(mean=stats[0], std=stats[1])\n",
    "# standard_transform_phase = transforms.Normalize(mean=stats[2], std=stats[3])\n",
    "\n",
    "\n",
    "print(train_transform)\n",
    "print(test_transform)\n",
    "\n",
    "# Make directories / delete them\n",
    "if not os.path.exists(full_save_path):\n",
    "    # Create the directory\n",
    "    os.makedirs(full_save_path)\n",
    "\n",
    "else: \n",
    "    user_input = input(f\"The directory specified has already been created. Would you like to delete the directory and replace with new data? (yes/no)\")\n",
    "\n",
    "    if user_input.lower() == \"yes\":\n",
    "        shutil.rmtree(full_save_path)\n",
    "        os.makedirs(full_save_path)\n",
    "    else:\n",
    "        print(\"Program execution canceled. Please change pathing inputs to save to a new directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_dataset = datasets.CIFAR100(data_path, train=True, transform=train_transform, download=True)\n",
    "test_dataset = datasets.CIFAR100(data_path, train=False, transform=test_transform, download=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(x, n_segments=196):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.permute(0, 2, 3, 1) # Change channels to be last dimension\n",
    "    x = x.cpu().numpy()\n",
    "\n",
    "    if not x.flags['C_CONTIGUOUS']:\n",
    "        x = x.copy(order='C')\n",
    "\n",
    "    assert x.flags['C_CONTIGUOUS']\n",
    "\n",
    "     # Iterate over each image in batch and get segmentation mask\n",
    "    save_mask = torch.zeros((B, H, W), device=DEVICE)\n",
    "    for i, img in enumerate(x):\n",
    "        cp_img = np.squeeze(img)\n",
    "\n",
    "        # slic = Slic(num_components=n_segments, min_size_factor=0)\n",
    "        # slic = SlicAvx2(num_components=n_segments, min_size_factor=0)\n",
    "        # segmentation_mask = slic.iterate(cp_img)\n",
    "        # print(i, len(np.unique(segmentation_mask)))\n",
    "        # assert len(np.unique(segmentation_mask)) == n_segments, f\"Got {len(np.unique(segmentation_mask))} segments from SLIC, but expected {n_segments}\"\n",
    "\n",
    "        segmentation_mask = np.zeros((224, 224))\n",
    "\n",
    "        for w in range(0, 224, 16):\n",
    "            for j in range(0, 224, 16):\n",
    "                segmentation_mask[w:w+16, j:j+16] = int(w/16 + (j/16)*14)\n",
    "\n",
    "        save_mask[i, :, :] = torch.from_numpy(segmentation_mask).to(DEVICE)\n",
    "        \n",
    "    # print(torch.unique(save_mask, return_counts=True))    \n",
    "    return save_mask\n",
    "\n",
    "def process_BoW(x, save_mask, n_segments=196):\n",
    "\n",
    "    # Format\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    B = x.shape[0]\n",
    "    \n",
    "    # Allocate\n",
    "    seg_out = torch.zeros((B, n_segments, 256*3))\n",
    "    pos_out = torch.zeros((B, n_segments, 5))\n",
    "\n",
    "    # TODO: Verify implementation\n",
    "    for i in tqdm(range(n_segments)):\n",
    "        # print(i)\n",
    "        # Get mask for segment i for all images in batch\n",
    "        binary_mask = (save_mask == i)\n",
    "\n",
    "        for j, image_mask in enumerate(binary_mask):\n",
    "            # Crop image j based on binary mask for segment i\n",
    "            cpu_image_mask = np.uint8(image_mask.cpu().numpy())\n",
    "            coords = cv2.findNonZero(cpu_image_mask)\n",
    "            bbox_x, bbox_y, bbox_w, bbox_h = cv2.boundingRect(coords)\n",
    "            cropped_image = x[j, bbox_y:bbox_y+bbox_h, bbox_x:bbox_x+bbox_w, :]\n",
    "\n",
    "            # Get cropped binary mask and find statistics needed for distribution\n",
    "            cropped_mask = image_mask[bbox_y:bbox_y+bbox_h, bbox_x:bbox_x+bbox_w]\n",
    "            num_zeros_false = torch.sum(~cropped_mask) # Number of zeros in each mask (to use in pdf calculation)\n",
    "            norm_factor = torch.sum(cropped_mask) # Number of pixels in each mask (divide in pdf calculation to shift to probability)\n",
    "            norm_factor[norm_factor == 0] = 1 # So we don't divide by 0\n",
    "\n",
    "            # Get unique distribution for each channel of the image\n",
    "            distribution = torch.stack([ torch.bincount(channel.flatten().to(torch.int), minlength=256) for channel in cropped_image.permute(2,0,1)], dim=-1) # Iterate over each channel. Find distribution and stack\n",
    "\n",
    "            distribution[0, :] = distribution[0, :] - num_zeros_false.unsqueeze(-1) # Subtract number of False values in binary mask from each image (as it was counted in distribution). Broadcasted across channels\n",
    "            distribution = distribution / norm_factor.unsqueeze(-1) # Divide by total number of pixels in mask to shift to a probability distribution    \n",
    "\n",
    "            # Save\n",
    "            # assert torch.sum(torch.isnan(distribution)).item() == 0, \"NaN element in the distribution\"\n",
    "            # assert torch.sum(distribution, dim=0).all() == 1, f\"Not a valid probability distribution, sum across al channels is {torch.sum(distribution)}, expected 3.0\"\n",
    "            # assert torch.sum(distribution) >= 0, \"Negative value\"\n",
    "            \n",
    "            seg_out[j, i, :] = distribution.flatten()\n",
    "        \n",
    "        # num_zeros_false = torch.sum(~binary_mask, axis=(1,2)) # Number of zeros in each mask (to use in pdf calculation)\n",
    "        # area = torch.sum(binary_mask, axis=(1,2)) # Number of pixels in each mask (divide in pdf calculation to shift to probability)\n",
    "        # norm_factor = area.clone()\n",
    "        # norm_factor[area == 0] = 1 # So that we don't divide by 0\n",
    "\n",
    "        # # Get segment data for all images in batch\n",
    "        # segmented_imgs = binary_mask.unsqueeze(-1) * x # Broadcast mask and get segment i in all images in batch (1000, 224, 224, 3)\n",
    "\n",
    "        # # Get unique distribution for each image and each channe;\n",
    "        # distribution = torch.stack([ torch.stack([ torch.bincount(channel.flatten().to(torch.int), minlength=256) for channel in img.permute(2,0,1)], dim=-1) for img in segmented_imgs]) # Iterate over each image. Iterate over each channel. Find distribution and stack\n",
    "\n",
    "        # distribution[:, 0, :] = distribution[:, 0, :] - num_zeros_false.unsqueeze(-1) # Subtract number of False values in binary mask from each image (as it was counted in distribution). Broadcasted across channels\n",
    "        # distribution = distribution / norm_factor.unsqueeze(-1).unsqueeze(-1) # Divide by total number of pixels in mask to shift to a probability distribution      \n",
    "\n",
    "\n",
    "        # Find positional info (Area, center coordinates, max width/height)\n",
    "        area = torch.sum(binary_mask, dim=(1,2)) / (binary_mask.shape[1] * binary_mask.shape[2])\n",
    "\n",
    "        # If the binary mask has any True values for segment i, then find the center coordinate. Else, return 0\n",
    "        centroid = torch.stack([ (torch.mean(torch.argwhere(img_mask).float(),axis=0) / torch.tensor(img_mask.shape, device=DEVICE)) if torch.argwhere(img_mask).numel() > 0 else torch.zeros((2), device=DEVICE) for img_mask in binary_mask])\n",
    "        center_x = centroid[:, 1]\n",
    "        center_y = centroid[:, 0]\n",
    "\n",
    "        # If the binary mask has any True values for segment i, then find the max width/height of the segment. Else, return 0\n",
    "        rect = torch.stack([ (1 + torch.max(torch.argwhere(img_mask), axis=0).values - torch.min(torch.argwhere(img_mask), axis=0).values) / torch.tensor(img_mask.shape, device=DEVICE) if torch.argwhere(img_mask).numel() > 0 else torch.zeros((2), device=DEVICE) for img_mask in binary_mask])\n",
    "\n",
    "        width = rect[:, 1]\n",
    "        height = rect[:, 0]\n",
    "\n",
    "        # Save\n",
    "        pos = torch.stack([area, center_x, center_y, width, height])\n",
    "        assert torch.sum(torch.isnan(pos)).item() == 0, \"NaN element in the positional stats\"\n",
    "        pos_save = torch.transpose(pos, 1, 0) #TODO: make this device (how does this work with DataParallel)\n",
    "        pos_out[:, i, :] = pos_save\n",
    "\n",
    "        # assert torch.sum(torch.isnan(distribution)).item() == 0, \"NaN element in the distribution\"\n",
    "        # seg_out[:, i, :] = distribution.reshape(B, -1)\n",
    "            \n",
    "    return seg_out, pos_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:20<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:25<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:23<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:23<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:25<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:25<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:37<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:23<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:25<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:24<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:25<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [05:25<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "data_type = \"train\"\n",
    "use = data_loader_train if data_type==\"train\" else data_loader_test\n",
    "\n",
    "# Iterate over dataloader\n",
    "for i, (inputs, labels) in enumerate(use):\n",
    "    print(i)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    inputs *= 255\n",
    "    inputs = inputs.to(torch.uint8)\n",
    "    \n",
    "\n",
    "    # Segment image, take FT, and find pos embed. \n",
    "    seg_mask = process_segment(inputs, n_segments=n_segments)\n",
    "\n",
    "    seg_out, pos_out = process_BoW(inputs, seg_mask, n_segments=n_segments)\n",
    "\n",
    "    save_data = torch.cat((seg_out, pos_out), dim=2).cpu().numpy() # Stack data and format for save\n",
    "\n",
    "    # Iterate over data and save\n",
    "    for i, data in enumerate(save_data):\n",
    "        label = labels[i]\n",
    "        class_name = class_names[label]\n",
    "        class_path = os.path.join(full_save_path, data_type, class_name)\n",
    "        # print(class_path)\n",
    "\n",
    "        # Create class folder if it does not exist\n",
    "        if not os.path.exists(class_path):\n",
    "            os.makedirs(class_path)\n",
    "\n",
    "        save_num = len(os.listdir(class_path)) \n",
    "        np.savez_compressed(os.path.join(class_path, f'{save_num}.npz'), data=data)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
