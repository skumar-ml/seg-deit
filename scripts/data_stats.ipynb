{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk138/miniconda3/envs/general/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from timm.data import create_transform\n",
    "import torch\n",
    "import numpy as np\n",
    "from fast_slic.avx2 import SlicAvx2\n",
    "import os\n",
    "import shutil\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# User variables\n",
    "data_path = \"/home/sk138/data/\"\n",
    "data_folder_name = \"cifar-100-python/\"\n",
    "\n",
    "input_size = 224\n",
    "num_workers = 10\n",
    "n_segments=196\n",
    "pin_mem = True\n",
    "n_points=64\n",
    "batch_size=1000\n",
    "DEVICE='cuda:0'\n",
    "\n",
    "# Transforms\n",
    "train_transform = create_transform(input_size, is_training=True, no_aug=True)\n",
    "test_transform = create_transform(input_size, is_training=False, no_aug=True)\n",
    "grayscale_transform = transforms.Grayscale()\n",
    "\n",
    "print(train_transform)\n",
    "print(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_dataset = datasets.CIFAR100(data_path, train=True, transform=train_transform, download=True)\n",
    "test_dataset = datasets.CIFAR100(data_path, train=False, transform=test_transform, download=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(x, n_segments=196):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.permute(0, 2, 3, 1) # Change channels to be last dimension\n",
    "    x = x.cpu().numpy()\n",
    "\n",
    "    if not x.flags['C_CONTIGUOUS']:\n",
    "        x = x.copy(order='C')\n",
    "\n",
    "    assert x.flags['C_CONTIGUOUS']\n",
    "\n",
    "     # Iterate over each image in batch and get segmentation mask\n",
    "    save_mask = torch.zeros((B, H, W), device=DEVICE)\n",
    "    for i, img in enumerate(x):\n",
    "        cp_img = np.squeeze(img)\n",
    "\n",
    "        # slic = Slic(num_components=n_segments, min_size_factor=0)\n",
    "        slic = SlicAvx2(num_components=n_segments, min_size_factor=0)\n",
    "        segmentation_mask = slic.iterate(cp_img)\n",
    "        # print(i, len(np.unique(segmentation_mask)))\n",
    "        # assert len(np.unique(segmentation_mask)) == n_segments, f\"Got {len(np.unique(segmentation_mask))} segments from SLIC, but expected {n_segments}\"\n",
    "        save_mask[i, :, :] = torch.from_numpy(segmentation_mask).to(DEVICE)\n",
    "        \n",
    "    return save_mask\n",
    "\n",
    "def process_ft(x, save_mask, n_segments=196, n_points=64, grayscale=True):\n",
    "\n",
    "    # Format\n",
    "    x = x.permute(0, 2, 3, 1).squeeze()\n",
    "    B = x.shape[0]\n",
    "    \n",
    "    # Allocate\n",
    "    seg_out = torch.zeros((B, n_segments, int(n_points * (n_points/2 + 1) * 2)))\n",
    "    pos_out = torch.zeros((B, n_segments, 5))\n",
    "\n",
    "    magnitude_sum = 0\n",
    "    magnitude_sum_2 = 0\n",
    "\n",
    "    phase_sum = 0\n",
    "    phase_sum_2 = 0\n",
    "\n",
    "    # TODO: Verify implementation\n",
    "    for i in range(n_segments):\n",
    "        # print(i)\n",
    "        # Get mask for segment i for all images in batch\n",
    "        binary_mask = (save_mask == i)\n",
    "        # print(binary_mask.shape)\n",
    "\n",
    "        # Get segment data for all images in batch\n",
    "        segmented_imgs = binary_mask * x\n",
    "\n",
    "        # Take FT and separate magnitude and phase info\n",
    "        # fourier_transform = torch.fft.fft2(segmented_imgs, s=(n_points, n_points))\n",
    "        fourier_transform = torch.fft.rfft2(segmented_imgs, s=(n_points, n_points))\n",
    "        magnitude = torch.abs(fourier_transform) \n",
    "        phase = torch.angle(fourier_transform) \n",
    "\n",
    "        assert torch.sum(torch.isnan(magnitude)).item() == 0, \"NaN element in the magnitude before normalization\"\n",
    "\n",
    "        # Normalize scales\n",
    "        # magnitude = magnitude / (1 if torch.max(magnitude)==0 else torch.max(magnitude))  # [0 1] -- divide by 1 if max is already 0.\n",
    "        phase = phase / torch.tensor(math.pi) # [-1 1]\n",
    "\n",
    "        # print(torch.max(magnitude))\n",
    "        # print(torch.max(phase))\n",
    "        # print(torch.min(phase))\n",
    "\n",
    "        assert torch.sum(torch.isnan(magnitude)).item() == 0, \"NaN element in the magnitude after normalization\"\n",
    "        \n",
    "        magnitude_sum += torch.sum(magnitude)\n",
    "        magnitude_sum_2 += torch.sum(magnitude ** 2)\n",
    "\n",
    "        phase_sum = torch.sum(phase)\n",
    "        phase_sum_2 = torch.sum(phase**2)\n",
    "\n",
    "        return magnitude_sum, magnitude_sum_2, phase_sum, phase_sum_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "data_type = \"train\"\n",
    "use = data_loader_train if data_type==\"train\" else data_loader_test\n",
    "\n",
    "magnitude_sum_tot = 0\n",
    "magnitude_sum_2_tot = 0\n",
    "phase_sum_tot = 0\n",
    "phase_sum_2_tot = 0\n",
    "\n",
    "# Iterate over dataloader\n",
    "for i, (inputs, labels) in enumerate(use):\n",
    "    print(i)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    inputs = inputs.to(torch.uint8)\n",
    "\n",
    "    # Segment image, take FT, and find pos embed. \n",
    "    seg_mask = process_segment(inputs, n_segments=n_segments)\n",
    "    input_gray = grayscale_transform(inputs)\n",
    "    temp1, temp2, temp3, temp4 = process_ft(input_gray, seg_mask, n_segments=n_segments, n_points=n_points)\n",
    "\n",
    "    magnitude_sum_tot += temp1\n",
    "    magnitude_sum_2_tot += temp2\n",
    "    phase_sum_tot += temp3\n",
    "    phase_sum_2_tot += temp4\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
