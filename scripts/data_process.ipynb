{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from timm.data import create_transform\n",
    "import torch\n",
    "import numpy as np\n",
    "from fast_slic.avx2 import SlicAvx2\n",
    "import os\n",
    "import shutil\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# User variables\n",
    "data_path = \"/home/sk138/data/\"\n",
    "data_folder_name = \"cifar-100-python/\"\n",
    "\n",
    "save_path = \"/home/sk138/data/cifar-100-python-segmented/\"\n",
    "input_size = 224\n",
    "num_workers = 10\n",
    "n_segments=196\n",
    "pin_mem = True\n",
    "n_points=64\n",
    "batch_size=1000\n",
    "DEVICE='cuda:1'\n",
    "\n",
    "# Pathing\n",
    "save_parent = f\"cifar-{n_segments}-{n_points}-standard/\"\n",
    "full_save_path = os.path.join(save_path, save_parent)\n",
    "\n",
    "# Transforms\n",
    "train_transform = create_transform(input_size, is_training=True, no_aug=True)\n",
    "test_transform = create_transform(input_size, is_training=False, no_aug=True)\n",
    "grayscale_transform = transforms.Grayscale()\n",
    "\n",
    "stats = torch.load('train_stats.pt')\n",
    "standard_transform_mag = transforms.Normalize(mean=stats[0], std=stats[1])\n",
    "standard_transform_phase = transforms.Normalize(mean=stats[2], std=stats[3])\n",
    "\n",
    "\n",
    "print(train_transform)\n",
    "print(test_transform)\n",
    "\n",
    "# Make directories / delete them\n",
    "if not os.path.exists(full_save_path):\n",
    "    # Create the directory\n",
    "    os.makedirs(full_save_path)\n",
    "\n",
    "else: \n",
    "    user_input = input(f\"The directory specified has already been created. Would you like to delete the directory and replace with new data? (yes/no)\")\n",
    "\n",
    "    if user_input.lower() == \"yes\":\n",
    "        shutil.rmtree(full_save_path)\n",
    "        os.makedirs(full_save_path)\n",
    "    else:\n",
    "        print(\"Program execution canceled. Please change pathing inputs to save to a new directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_dataset = datasets.CIFAR100(data_path, train=True, transform=train_transform, download=True)\n",
    "test_dataset = datasets.CIFAR100(data_path, train=False, transform=test_transform, download=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(x, n_segments=196):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.permute(0, 2, 3, 1) # Change channels to be last dimension\n",
    "    x = x.cpu().numpy()\n",
    "\n",
    "    if not x.flags['C_CONTIGUOUS']:\n",
    "        x = x.copy(order='C')\n",
    "\n",
    "    assert x.flags['C_CONTIGUOUS']\n",
    "\n",
    "     # Iterate over each image in batch and get segmentation mask\n",
    "    save_mask = torch.zeros((B, H, W), device=DEVICE)\n",
    "    for i, img in enumerate(x):\n",
    "        cp_img = np.squeeze(img)\n",
    "\n",
    "        # slic = Slic(num_components=n_segments, min_size_factor=0)\n",
    "        slic = SlicAvx2(num_components=n_segments, min_size_factor=0)\n",
    "        segmentation_mask = slic.iterate(cp_img)\n",
    "        # print(i, len(np.unique(segmentation_mask)))\n",
    "        # assert len(np.unique(segmentation_mask)) == n_segments, f\"Got {len(np.unique(segmentation_mask))} segments from SLIC, but expected {n_segments}\"\n",
    "\n",
    "        save_mask[i, :, :] = torch.from_numpy(segmentation_mask).to(DEVICE)\n",
    "        \n",
    "    return save_mask\n",
    "\n",
    "def process_ft(x, save_mask, n_segments=196, n_points=64, grayscale=True):\n",
    "\n",
    "    # Format\n",
    "    x = x.permute(0, 2, 3, 1).squeeze()\n",
    "    B = x.shape[0]\n",
    "    \n",
    "    # Allocate\n",
    "    seg_out = torch.zeros((B, n_segments, int(n_points * (n_points/2 + 1) * 2)))\n",
    "    pos_out = torch.zeros((B, n_segments, 5))\n",
    "\n",
    "    # TODO: Verify implementation\n",
    "    for i in range(n_segments):\n",
    "        # print(i)\n",
    "        # Get mask for segment i for all images in batch\n",
    "        binary_mask = (save_mask == i)\n",
    "        # print(binary_mask.shape)\n",
    "\n",
    "        # Get segment data for all images in batch\n",
    "        segmented_imgs = binary_mask * x\n",
    "\n",
    "        # Take FT and separate magnitude and phase info\n",
    "        # fourier_transform = torch.fft.fft2(segmented_imgs, s=(n_points, n_points))\n",
    "        fourier_transform = torch.fft.rfft2(segmented_imgs, s=(n_points, n_points))\n",
    "        magnitude = torch.abs(fourier_transform) \n",
    "        phase = torch.angle(fourier_transform) \n",
    "\n",
    "        assert torch.sum(torch.isnan(magnitude)).item() == 0, \"NaN element in the magnitude before normalization\"\n",
    "\n",
    "        # Normalize scales & standardize data according to dataset statistics\n",
    "        # magnitude = magnitude / (1 if torch.max(magnitude)==0 else torch.max(magnitude))  # [0 1] -- divide by 1 if max is already 0.\n",
    "        magnitude = standard_transform_mag(magnitude)\n",
    "        phase = phase / torch.tensor(math.pi) # [-1 1]\n",
    "        phase = standard_transform_phase(phase)\n",
    "\n",
    "        # print(torch.max(magnitude))\n",
    "        # print(torch.max(phase))\n",
    "        # print(torch.min(phase))\n",
    "\n",
    "        assert torch.sum(torch.isnan(magnitude)).item() == 0, \"NaN element in the magnitude after normalization\"\n",
    "        assert torch.sum(torch.isnan(phase)).item() == 0, \"NaN element in the magnitude\"\n",
    "\n",
    "        # Save\n",
    "        to_save = torch.stack((magnitude, phase)).reshape((fourier_transform.shape[0], -1))\n",
    "        seg_out[:, i, :] = to_save\n",
    "\n",
    "        # Find positional info (Area, center coordinates, max width/height)\n",
    "        area = torch.sum(binary_mask, axis=(1,2)) / (binary_mask.shape[1] * binary_mask.shape[2])\n",
    "\n",
    "        # If the binary mask has any True values for segment i, then find the center coordinate. Else, return 0\n",
    "        centroid = torch.stack([ (torch.mean(torch.argwhere(img_mask).float(),axis=0)) / torch.tensor(img_mask.shape, device=DEVICE) if torch.argwhere(img_mask).numel() > 0 else torch.zeros((2), device=DEVICE) for img_mask in binary_mask])\n",
    "        center_x = centroid[:, 0]\n",
    "        center_y = centroid[:, 1]\n",
    "\n",
    "        # If the binary mask has any True values for segment i, then find the max width/height of the segment. Else, return 0\n",
    "        rect = torch.stack([ (torch.max(torch.argwhere(img_mask), axis=0).values - torch.min(torch.argwhere(img_mask), axis=0).values) / torch.tensor(img_mask.shape, device=DEVICE) if torch.argwhere(img_mask).numel() > 0 else torch.zeros((2), device=DEVICE) for img_mask in binary_mask])\n",
    "\n",
    "        width = rect[:, 0]\n",
    "        height = rect[:, 1]\n",
    "\n",
    "        # Save\n",
    "        pos = torch.stack([area, center_x, center_y, width, height])\n",
    "        assert torch.sum(torch.isnan(pos)).item() == 0, \"NaN element in the positional stats\"\n",
    "        pos_save = torch.t(pos) #TODO: make this device (how does this work with DataParallel)\n",
    "        pos_out[:, i, :] = pos_save\n",
    "            \n",
    "    return seg_out, pos_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "data_type = \"test\"\n",
    "use = data_loader_train if data_type==\"train\" else data_loader_test\n",
    "\n",
    "# Iterate over dataloader\n",
    "for i, (inputs, labels) in enumerate(use):\n",
    "    print(i)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    inputs = inputs.to(torch.uint8)\n",
    "\n",
    "    # Segment image, take FT, and find pos embed. \n",
    "    seg_mask = process_segment(inputs, n_segments=n_segments)\n",
    "    input_gray = grayscale_transform(inputs)\n",
    "    seg_out, pos_out = process_ft(input_gray, seg_mask, n_segments=n_segments, n_points=n_points)\n",
    "    save_data = torch.cat((seg_out, pos_out), dim=2).cpu().numpy() # Stack data and format for save\n",
    "\n",
    "    # Iterate over data and save\n",
    "    for i, data in enumerate(save_data):\n",
    "        label = labels[i]\n",
    "        class_name = class_names[label]\n",
    "        class_path = os.path.join(full_save_path, data_type, class_name)\n",
    "        # print(class_path)\n",
    "\n",
    "        # Create class folder if it does not exist\n",
    "        if not os.path.exists(class_path):\n",
    "            os.makedirs(class_path)\n",
    "\n",
    "        save_num = len(os.listdir(class_path)) \n",
    "        np.savez_compressed(os.path.join(class_path, f'{save_num}.npz'), data=data)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
