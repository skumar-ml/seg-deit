{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage\n",
    "\n",
    "from fast_slic import Slic\n",
    "from fast_slic.avx2 import SlicAvx2\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_segment(x, n_segments=196):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.permute(0, 2, 3, 1) # Change channels to be last dimension\n",
    "    x = x.numpy()\n",
    "\n",
    "     # Iterate over each image in batch and get segmentation mask\n",
    "    start_time = time.time()\n",
    "    save_mask = np.zeros((B, H, W))\n",
    "    for i, img in enumerate(x):\n",
    "        cp_img = np.squeeze(img)\n",
    "\n",
    "        segmentation_mask = skimage.segmentation.slic(cp_img, n_segments=n_segments, start_label=0, min_size_factor=0)\n",
    "        save_mask[i, :, :] = segmentation_mask\n",
    "\n",
    "    print(f\"Time to get segmentation masks (OG): {time.time() - start_time}\")\n",
    "    return save_mask\n",
    "\n",
    "def test_segment(x, n_segments=196):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.permute(0, 2, 3, 1) # Change channels to be last dimension\n",
    "    x = x.numpy()\n",
    "\n",
    "     # Iterate over each image in batch and get segmentation mask\n",
    "    start_time = time.time()\n",
    "    save_mask = np.zeros((B, H, W))\n",
    "    for i, img in enumerate(x):\n",
    "        cp_img = np.squeeze(img)\n",
    "\n",
    "        # slic = Slic(num_components=n_segments, min_size_factor=0)\n",
    "        slic = SlicAvx2(num_components=n_segments, min_size_factor=0)\n",
    "        segmentation_mask = slic.iterate(cp_img)\n",
    "        save_mask[i, :, :] = segmentation_mask\n",
    "        # print(len(np.unique(segmentation_mask)))\n",
    "\n",
    "    print(f\"Time to get segmentation masks (NEW): {time.time() - start_time}\")\n",
    "    return save_mask\n",
    "\n",
    "\n",
    "def original_ft(x, save_mask, n_segments=196, n_points=64, grayscale=True):\n",
    "\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    x = x.cpu().numpy()\n",
    "    B = x.shape[0]\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    seg_out = torch.zeros((B, n_segments, n_points * n_points * 2))\n",
    "    pos_out = torch.zeros((B, n_segments, 5))\n",
    "\n",
    "    ft_time = time.time()\n",
    "\n",
    "    for j, img in enumerate(x):\n",
    "\n",
    "        unique_integers = np.unique(save_mask[j], return_counts=True)\n",
    "\n",
    "        # Iterate over number of tokens we want\n",
    "        for i in range(n_segments):                    \n",
    "            # If token ID not in mask, we must set to [PAD]\n",
    "            if i not in unique_integers[0]:\n",
    "                seg_out[j, i, :] = torch.zeros((1, 1, n_points*n_points*2))\n",
    "                pos_out[j, i, :] = torch.zeros((1, 1, 5))\n",
    "\n",
    "            # Else, token exists and we must extract freq content & positional embeddings\n",
    "            else:                        \n",
    "                # Get each segment and take FT. Unroll and save\n",
    "                binary_mask = (save_mask[j] == i)\n",
    "                segmented_img = img * np.expand_dims(binary_mask, axis=-1)\n",
    "\n",
    "                # Convert to grayscale if specified\n",
    "                if grayscale:\n",
    "                    cp_img = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Take FT\n",
    "                fourier_transform = np.fft.fft2(cp_img, s=(n_points, n_points))\n",
    "\n",
    "                # Extract magnitude and phase information\n",
    "                magnitude = np.abs(fourier_transform)\n",
    "                phase = np.angle(fourier_transform)\n",
    "\n",
    "                # Save FT info\n",
    "                to_save = np.stack((magnitude, phase)).flatten(order=\"F\")                    \n",
    "                assert to_save.shape[0] == seg_out.shape[2]\n",
    "                seg_out[j, i, :] = torch.from_numpy(to_save)\n",
    "\n",
    "                #### Get position embedding info (static) \n",
    "                # Area\n",
    "                area = np.sum(binary_mask) / binary_mask.size\n",
    "\n",
    "                # Center (Average)\n",
    "                center_x = np.average(np.where(binary_mask)[1]) / binary_mask.shape[1]\n",
    "                center_y = np.average(np.where(binary_mask)[0]) / binary_mask.shape[0]\n",
    "\n",
    "                # Width/Height\n",
    "                # print(np.where(binary_mask)[1].shape)\n",
    "                width = (np.max(np.where(binary_mask)[1]) - np.min(np.where(binary_mask)[1])) / binary_mask.shape[1]\n",
    "                height = (np.max(np.where(binary_mask)[0]) - np.min(np.where(binary_mask)[0])) / binary_mask.shape[0]\n",
    "\n",
    "                # Store in array and convert to tensor on device\n",
    "                pos_save = torch.from_numpy(np.array([area, center_x, center_y, width, height])) #TODO: make this device (how does this work with DataParallel)\n",
    "                pos_out[j, i, :] = pos_save\n",
    "\n",
    "    print(f\"Time to get FT + pos info (OG): {time.time() - start_time}\")\n",
    "    return seg_out, pos_out\n",
    "\n",
    "def test_ft(x, save_mask, n_segments=196, n_points=64, grayscale=True):\n",
    "\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    x = x.cpu().numpy()\n",
    "    B = x.shape[0]\n",
    "\n",
    "    # Sanity check\n",
    "    test = save_mask.reshape(save_mask.shape[0], -1) # Flatten H/W info\n",
    "    test = np.apply_along_axis(np.unique, 1, test)\n",
    "    test = np.max(test, axis=1)\n",
    "    assert np.all(test == (n_segments-1))\n",
    "    \n",
    "    seg_out = torch.zeros((B, n_segments, n_points * n_points * 2))\n",
    "    pos_out = torch.zeros((B, n_segments, 5))\n",
    "\n",
    "    ft_time = time.time()\n",
    "    x = np.array([cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY) for color_image in x])\n",
    "\n",
    "    # TODO: Verify implementation\n",
    "    for i in range(n_segments):\n",
    "        binary_mask = (save_mask == i)\n",
    "\n",
    "        segmented_imgs = binary_mask * x\n",
    "\n",
    "        fourier_transform = np.fft.fft2(segmented_imgs, s=(n_points, n_points))\n",
    "\n",
    "        magnitude = np.abs(fourier_transform)\n",
    "        phase = np.angle(fourier_transform)\n",
    "\n",
    "        to_save = np.stack((magnitude, phase)).reshape((fourier_transform.shape[0], -1), order=\"F\") \n",
    "        seg_out[:, i, :] = torch.from_numpy(to_save)\n",
    "\n",
    "        area = np.sum(binary_mask, axis=(1,2)) / (binary_mask.shape[1] * binary_mask.shape[2])\n",
    "\n",
    "        centroid = np.array([np.mean(np.argwhere(img_mask),axis=0) / np.array(img_mask.shape) for img_mask in binary_mask])\n",
    "        center_x = centroid[:, 0]\n",
    "        center_y = centroid[:, 1]\n",
    "\n",
    "        rect = np.array([(np.max(np.argwhere(img_mask), axis=0) - np.min(np.argwhere(img_mask), axis=0)) / np.array(img_mask.shape) for img_mask in binary_mask])\n",
    "\n",
    "        width = rect[:, 0]\n",
    "        height = rect[:, 1]\n",
    "\n",
    "        pos_save = torch.from_numpy(np.array([area, center_x, center_y, width, height]).transpose()) #TODO: make this device (how does this work with DataParallel)\n",
    "        pos_out[:, i, :] = pos_save\n",
    "            \n",
    "\n",
    "    print(f\"Time to get FT +pos info (NEW): {time.time() - ft_time}\")\n",
    "    return seg_out, pos_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get segmentation masks (OG): 13.031810522079468\n",
      "Time to get FT + pos info (OG): 48.90101361274719\n"
     ]
    }
   ],
   "source": [
    "# with Image.open(\"test_img.png\") as f:\n",
    "#    image = np.array(f)\n",
    "\n",
    "# image = cv2.resize(image, (224, 224))\n",
    "# data = np.tile(image, (256, 1, 1, 1))\n",
    "\n",
    "# Randomly generate image data\n",
    "data = np.random.randint(0, 256, size=(256, 224, 224, 3), dtype=np.uint8)\n",
    "data = (torch.from_numpy(data)).permute(0, 3, 1, 2)\n",
    "\n",
    "# Test with original implementation\n",
    "og_segments = original_segment(data)\n",
    "og_seg, og_pos = original_ft(data, og_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get segmentation masks (NEW): 0.6145634651184082\n",
      "(256, 224, 224)\n",
      "Time to get FT +pos info (NEW): 24.836795568466187\n"
     ]
    }
   ],
   "source": [
    "new_segments = test_segment(data)\n",
    "print(new_segments.shape)\n",
    "test_seg, test_pos = test_ft(data, new_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
